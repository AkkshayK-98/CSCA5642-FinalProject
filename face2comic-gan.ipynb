{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_filenames(face_dir):\n",
    "    return sorted(os.listdir(face_dir))  # assumes same names in face/ and comics/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43677efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(root_dir, image_size=256):\n",
    "    face_dir = os.path.join(root_dir, 'face')\n",
    "    comic_dir = os.path.join(root_dir, 'comics')\n",
    "    filenames = get_image_filenames(face_dir)\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.Resize((image_size, image_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "\n",
    "    def dataset_fn(index):\n",
    "        fname = filenames[index]\n",
    "        face_path = os.path.join(face_dir, fname)\n",
    "        comic_path = os.path.join(comic_dir, fname)\n",
    "\n",
    "        face = Image.open(face_path).convert(\"RGB\")\n",
    "        comic = Image.open(comic_path).convert(\"RGB\")\n",
    "\n",
    "        face = transform(face)\n",
    "        comic = transform(comic)\n",
    "\n",
    "        return {\n",
    "            'face': face,\n",
    "            'comic': comic,\n",
    "            'filename': fname\n",
    "        }\n",
    "\n",
    "    return dataset_fn, len(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404620b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_from_fn(dataset_fn, dataset_len, batch_size=16, shuffle=True, num_workers=2, subset_indices=None):\n",
    "    class FunctionalDataset(Dataset):\n",
    "        def __len__(self):\n",
    "            return len(subset_indices) if subset_indices is not None else dataset_len\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            idx = subset_indices[idx] if subset_indices is not None else idx\n",
    "            return dataset_fn(idx)\n",
    "\n",
    "    return DataLoader(FunctionalDataset(), batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset function and length\n",
    "dataset_fn, dataset_len = get_dataset('archive/face2comics', image_size=256)\n",
    "\n",
    "# Create subset with the first 500 images\n",
    "subset_indices = list(range(100))  # First 500 images\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "dataloader = get_dataloader_from_fn(dataset_fn, dataset_len, batch_size=4, shuffle=True, num_workers=0, subset_indices=subset_indices)\n",
    "\n",
    "# Check if it loads properly\n",
    "for batch in dataloader:\n",
    "    print(batch['face'].shape, batch['comic'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8189701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_real_vs_comic(real, comic, max_images=8):\n",
    "    real = real[:max_images]\n",
    "    comic = comic[:max_images]\n",
    "\n",
    "    # De-normalize from [-1, 1] back to [0, 1]\n",
    "    real = (real * 0.5) + 0.5\n",
    "    comic = (comic * 0.5) + 0.5\n",
    "\n",
    "    fig, axes = plt.subplots(2, max_images, figsize=(3 * max_images, 6))\n",
    "\n",
    "    for i in range(max_images):\n",
    "        axes[0, i].imshow(real[i].permute(1, 2, 0).cpu().numpy())\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Real\")\n",
    "\n",
    "        axes[1, i].imshow(comic[i].permute(1, 2, 0).cpu().numpy())\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Comic\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    show_real_vs_comic(batch['face'], batch['comic'], max_images=4)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d39342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pixel_histogram(image_tensor, title=\"Histogram\"):\n",
    "    img = image_tensor[0]  # Take first image in batch\n",
    "    img = (img * 0.5) + 0.5  # De-normalize to [0, 1]\n",
    "    img = img.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i, color in enumerate(['r', 'g', 'b']):\n",
    "        plt.hist(img[..., i].ravel(), bins=256, color=color, alpha=0.5, label=color)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee176cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    plot_pixel_histogram(batch['face'], title=\"Real Face Histogram\")\n",
    "    plot_pixel_histogram(batch['comic'], title=\"Comic Histogram\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c182b",
   "metadata": {},
   "source": [
    "U-Net Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling block\n",
    "def down_block(in_channels, out_channels, normalize=True):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1)]\n",
    "    if normalize:\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "    layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Upsampling block\n",
    "def up_block(in_channels, out_channels, dropout=0.0):\n",
    "    layers = [\n",
    "        nn.ConvTranspose2d(in_channels, out_channels, 4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if dropout:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Full U-Net Generator\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        # Encoder\n",
    "        self.d1 = down_block(3, 64, normalize=False)  # No norm in first layer\n",
    "        self.d2 = down_block(64, 128)\n",
    "        self.d3 = down_block(128, 256)\n",
    "        self.d4 = down_block(256, 512)\n",
    "        self.d5 = down_block(512, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.u1 = up_block(512, 512)\n",
    "        self.u2 = up_block(1024, 256)\n",
    "        self.u3 = up_block(512, 128)\n",
    "        self.u4 = up_block(256, 64)\n",
    "\n",
    "        # Final output layer\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        d1_out = self.d1(x)\n",
    "        d2_out = self.d2(d1_out)\n",
    "        d3_out = self.d3(d2_out)\n",
    "        d4_out = self.d4(d3_out)\n",
    "        d5_out = self.d5(d4_out)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        u1_out = self.u1(d5_out)\n",
    "        u1_out = torch.cat((u1_out, d4_out), dim=1)\n",
    "\n",
    "        u2_out = self.u2(u1_out)\n",
    "        u2_out = torch.cat((u2_out, d3_out), dim=1)\n",
    "\n",
    "        u3_out = self.u3(u2_out)\n",
    "        u3_out = torch.cat((u3_out, d2_out), dim=1)\n",
    "\n",
    "        u4_out = self.u4(u3_out)\n",
    "        u4_out = torch.cat((u4_out, d1_out), dim=1)\n",
    "\n",
    "        output = self.final(u4_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf925b",
   "metadata": {},
   "source": [
    "LightResNet Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual block\n",
    "def residual_block(in_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(in_channels)\n",
    "    )\n",
    "\n",
    "# Full LightResNet Generator\n",
    "class LightResNetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightResNetGenerator, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            residual_block(256),\n",
    "            residual_block(256),\n",
    "            residual_block(256)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        e = self.encoder(x)\n",
    "        r = self.res_blocks(e)\n",
    "        out = self.decoder(r)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e8deb",
   "metadata": {},
   "source": [
    "PatchGAN Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1145a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 4, stride=2, padding=1),  # input is real+fake images stacked\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_real, x_fake):\n",
    "        # Concatenate real and generated images along the channel dimension\n",
    "        x = torch.cat((x_real, x_fake), dim=1)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d87092",
   "metadata": {},
   "source": [
    "LightResNet Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01154cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions for LightResNet (GAN loss only)\n",
    "\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def gan_loss(predicted, target_is_real):\n",
    "    \"\"\"Calculates standard GAN loss\"\"\"\n",
    "    label_smooth = 0.1  # Set label smoothing factor\n",
    "    if target_is_real:\n",
    "        target = torch.ones_like(predicted) * (1 - label_smooth)  # Real labels are slightly less than 1\n",
    "    else:\n",
    "        target = torch.zeros_like(predicted) + label_smooth  # Fake labels are slightly more than 0\n",
    "    return bce_loss(predicted, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80363725",
   "metadata": {},
   "source": [
    "U-Net Generator Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions for U-Net (GAN + L1)\n",
    "\n",
    "l1_loss = nn.L1Loss()\n",
    "\n",
    "def unet_combined_loss(pred_fake, pred_real, fake_image, target_image, lambda_L1=100):\n",
    "    \"\"\"\n",
    "    pred_fake: output from discriminator on fake images\n",
    "    pred_real: output from discriminator on real images\n",
    "    fake_image: generated image\n",
    "    target_image: ground truth image\n",
    "    \"\"\"\n",
    "    gan = gan_loss(pred_fake, True)  # Generator wants to fool the discriminator\n",
    "    l1 = l1_loss(fake_image, target_image) * lambda_L1\n",
    "    return gan + l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helper functions\n",
    "def plot_loss_curves(loss_D_list, loss_G_list):\n",
    "    epochs = range(len(loss_D_list))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot Discriminator Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss_D_list, label='Discriminator Loss')\n",
    "    plt.title('Discriminator Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    # Plot Generator Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss_G_list, label='Generator Loss')\n",
    "    plt.title('Generator Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display side-by-side image comparison every 5 epochs\n",
    "def display_images(input_image, real_image, fake_image, epoch, num_images=1):\n",
    "    input_image = input_image[:num_images].cpu().detach().numpy()\n",
    "    real_image = real_image[:num_images].cpu().detach().numpy()\n",
    "    fake_image = fake_image[:num_images].cpu().detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(3, num_images, i+1)\n",
    "        plt.imshow(input_image[i].transpose(1, 2, 0))\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, num_images, i+1+num_images)\n",
    "        plt.imshow(real_image[i].transpose(1, 2, 0))\n",
    "        plt.title('Real Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, num_images, i+1+2*num_images)\n",
    "        plt.imshow(fake_image[i].transpose(1, 2, 0))\n",
    "        plt.title(f'Generated Image (Epoch {epoch})')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(generator, discriminator, dataloader, num_epochs=100, device='cuda', lambda_L1=100, learning_rate=2e-4, use_l1=True):\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    \n",
    "    # Optimizers\n",
    "    opt_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    opt_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss tracking lists\n",
    "    loss_D_list = []\n",
    "    loss_G_list = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "        epoch_loss_D = 0\n",
    "        epoch_loss_G = 0\n",
    "        for idx, data in enumerate(dataloader):\n",
    "            input_image = data['face'].to(device)\n",
    "            target_image = data['comic'].to(device)\n",
    "\n",
    "            # === Train Discriminator ===\n",
    "            opt_D.zero_grad()\n",
    "\n",
    "            # Real pair\n",
    "            pred_real = discriminator(input_image, target_image)\n",
    "            loss_real = gan_loss(pred_real, True)\n",
    "\n",
    "            # Fake pair\n",
    "            fake_image = generator(input_image)\n",
    "            pred_fake = discriminator(input_image, fake_image.detach())  # Detach to avoid gradients to G\n",
    "            loss_fake = gan_loss(pred_fake, False)\n",
    "\n",
    "            # Total discriminator loss\n",
    "            loss_D = (loss_real + loss_fake) * 0.5\n",
    "            loss_D.backward()\n",
    "            opt_D.step()\n",
    "\n",
    "            epoch_loss_D += loss_D.item()\n",
    "\n",
    "            # === Train Generator ===\n",
    "            opt_G.zero_grad()\n",
    "\n",
    "            # Generator tries to fool discriminator\n",
    "            pred_fake_for_g = discriminator(input_image, fake_image)\n",
    "\n",
    "            if use_l1:\n",
    "                loss_G = unet_combined_loss(pred_fake_for_g, pred_real, fake_image, target_image, lambda_L1)\n",
    "            else:\n",
    "                loss_G = gan_loss(pred_fake_for_g, True)\n",
    "\n",
    "            loss_G.backward()\n",
    "            opt_G.step()\n",
    "\n",
    "            epoch_loss_G += loss_G.item()\n",
    "\n",
    "            if idx % 50 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}] Batch [{idx}/{len(dataloader)}] Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}\")\n",
    "        \n",
    "        # Store average losses for this epoch\n",
    "        loss_D_list.append(epoch_loss_D / len(dataloader))\n",
    "        loss_G_list.append(epoch_loss_G / len(dataloader))\n",
    "        \n",
    "        # Display comparison of generated images every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            display_images(input_image, target_image, fake_image, epoch)\n",
    "\n",
    "    # Plot loss curves after training\n",
    "    plot_loss_curves(loss_D_list, loss_G_list)\n",
    "\n",
    "    return loss_D_list, loss_G_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models first\n",
    "#lightresnet_generator = build_lightresnet_generator()\n",
    "#unet_generator = build_unet_generator()\n",
    "#patchgan_discriminator = build_patchgan_discriminator()\n",
    "\n",
    "unet_generator = UNetGenerator()\n",
    "lightresnet_generator = LightResNetGenerator()\n",
    "discriminator = PatchGANDiscriminator()\n",
    "\n",
    "# Move to device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Divice: {device}\")\n",
    "#generator = generator.to(device)\n",
    "#discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning settings\n",
    "lambda_L1_values = [50, 100, 200]  # Values for lambda_L1\n",
    "learning_rate_values = [1e-4, 2e-4, 5e-4]  # Values for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8250b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to perform hyperparameter tuning\n",
    "def hyperparameter_tuning(generator, discriminator, dataloader, device='cuda', num_epochs=50, use_l1=True):\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for lambda_L1 in lambda_L1_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            print(f\"\\nTraining with lambda_L1={lambda_L1}, learning_rate={learning_rate}\")\n",
    "            #generator = generator_class()  # Assuming a function that returns a new generator model\n",
    "            # Set up optimizers with the current learning rate\n",
    "            #opt_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "            \n",
    "            # Train the model with current hyperparameters\n",
    "            loss_D_list, loss_G_list = train_model(generator, discriminator, dataloader, num_epochs, device, lambda_L1, learning_rate, use_l1)\n",
    "\n",
    "            # Use the final generator loss as a performance measure (can be modified for your needs)\n",
    "            final_loss_G = loss_G_list[-1]  # Get the final generator loss\n",
    "\n",
    "            # Update best parameters based on loss\n",
    "            if final_loss_G < best_loss:\n",
    "                best_loss = final_loss_G\n",
    "                best_params = {\n",
    "                    'lambda_L1': lambda_L1,\n",
    "                    'learning_rate': learning_rate\n",
    "                }\n",
    "\n",
    "            # Visualize losses (this can also be adjusted as needed)\n",
    "            plot_losses(loss_D_list, loss_G_list)\n",
    "\n",
    "    print(f\"\\nBest Parameters: lambda_L1={best_params[0]}, learning_rate={best_params[1]}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(unet_generator, patchgan_discriminator, dataloader, num_epochs=200, device='cuda', use_l1=True)\n",
    "best_params = hyperparameter_tuning(unet_generator, discriminator, dataloader, device, use_l1=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adbf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(lightresnet_generator, patchgan_discriminator, dataloader, num_epochs=200, device='cuda', use_l1=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
